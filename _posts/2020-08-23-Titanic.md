---
layout: post
title:  "Titanic"
date:   2020-08-23 19:14:00 -0500
category: Machine Learning
---

Análisis de los supervivientes del Titanic, creación de modelo de Machine Learning 
que predice si un pasajero sobrevivió o murió durante el naufragio.

<!--more-->
El hundimiento del RMS Titanic es uno de los mayores
naufragios de la historia. En abril de 1912 durante su viaje inaugural, el Titanic
se hundió después de colisionar con un iceberg, matando 1502 de 2224 pasajeros y
tripulación. Después de esta tragedia sensacional la comunidad internacional impulsó la
creación de mejores regularizaciones para una mejor seguridad de los barcos.

Una de las razones de que el naufragio tuviese muchas pérdidas de vidas fue que tenían
suficientes salvavidas para los pasajeros y tripulación. A pesar de que hubo mucha
suerte involucrada en la supervivencia del hundimiento, algunos grupos tuvieron
mayor probabilidad de sobrevivir que otros, tales como mujeres, niños y la clase alta.

---

Primeras 5 filas de los datos a analizar valores de los datos

<div class="table-wrapper">
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>

# Completar los datos

Buscaremos cuantos valores nulos se encuentran en el conjunto de datos

|PassengerId |     0|
|Survived    |     0|
|Pclass      |     0|
|Name        |     0|
|Sex         |     0|
|Age         |   263|
|SibSp       |     0|
|Parch       |     0|
|Ticket      |     0|
|Fare        |     1|
|Cabin       |  1014|
|Embarked    |     2|
|dtype: |int64|

Se encuentran 263 datos nulos en la columna de edad, 1014 en la columna de la cabina,
2 en la ciudad donde embarcaron y uno en la tarifa del boleto.

Sustituiremos los valores nulos de edad y de la tarifa usando la media de edad de 
los datos que sí conocemos de sus respectivas columnas, mientras que en la columna de
embarcamiento los remplazaremos con 0's.

Borraremos la columna de identificación del pasajero y del ticket ya que no nos
provee de información util, también eliminaremos la cabina, pero esta vez lo haremos 
ya que más de la mitad de los datos de esa columna están perdidos.

```python
for dataset in data_cleaner:    

    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)

    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)

    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)
    
drop_column = ['PassengerId','Cabin', 'Ticket']
data1.drop(drop_column, axis=1, inplace = True)
```

Verifiquemos que no hay más datos nulos.

|Survived|    0|
|Pclass  |    0|
|Name    |    0|
|Sex     |    0|
|Age     |    0|
|SibSp   |    0|
|Parch   |    0|
|Fare    |    0|
|Embarked|    0|
|dtype: |int64|

Crearemos una columna que nos cuente el tamaño de su familia a bordo, usando las columnas
hermanos/cónyuge y padres/hijos, también se hará una columna que diga si el pasajero 
viaja solo o no, adicionalmente crearemos una columna con el titulo de la persona, 
obtendremos este campo con la columna de nombre; Además crearemos grupos de edades y de 
tarifas para que sea más fácil para el modelo interpretar los datos.

```python
for dataset in data_cleaner:    
    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1

    dataset['IsAlone'] = 1
    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0

    dataset['Title'] = dataset['Name'].str.split(", ", expand=True)[1]\
        .str.split(".", expand=True)[0]

    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)

    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)
```

Miraremos las primeras 5 filas del conjunto de datos modificado.

<div class="table-wrapper">
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
      <th>FamilySize</th>
      <th>IsAlone</th>
      <th>Title</th>
      <th>FareBin</th>
      <th>AgeBin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>S</td>
      <td>2</td>
      <td>0</td>
      <td>Mr</td>
      <td>(-0.001, 7.91]</td>
      <td>(16.0, 32.0]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C</td>
      <td>2</td>
      <td>0</td>
      <td>Mrs</td>
      <td>(31.0, 512.329]</td>
      <td>(32.0, 48.0]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>S</td>
      <td>1</td>
      <td>1</td>
      <td>Miss</td>
      <td>(7.91, 14.454]</td>
      <td>(16.0, 32.0]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>S</td>
      <td>2</td>
      <td>0</td>
      <td>Mrs</td>
      <td>(31.0, 512.329]</td>
      <td>(32.0, 48.0]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>S</td>
      <td>1</td>
      <td>1</td>
      <td>Mr</td>
      <td>(7.91, 14.454]</td>
      <td>(32.0, 48.0]</td>
    </tr>
  </tbody>
</table>
</div>



## Convertir formatos

Usaremos un codificador de etiquetas para las columnas con variables categóricas.

```python
label = LabelEncoder()
for dataset in data_cleaner:    
    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])
    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])
    dataset['Title_Code'] = label.fit_transform(dataset['Title'])
    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])
    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])
```
Columnas originales

|Original X Y|'Survived'|'Sex'|'Pclass'|'Embarked'|'Title'|'SibSp'|
||'Parch'|'Age'|'Fare'| 'FamilySize'|'IsAlone'||
    
Columnas en cajas

|Bin X Y|'Survived'|'Sex_Code'|'Pclass'|'Embarked_Code'|
||'Title_Code'|'FamilySize'|'AgeBin_Code'|'FareBin_Code'|
    
Columnas con variables ficticias

|Dummy X Y|'Survived'|'Pclass'|'SibSp'|'Parch'|'Age'|
||'Fare'|'FamilySize'|'IsAlone'|'Sex_female'|'Sex_male'|
||'Embarked_C'|'Embarked_Q'|'Embarked_S'|'Title_Master'|'Title_Misc'|
||'Title_Miss'|'Title_Mr'|'Title_Mrs'|
    
Primeras 5 filas del conjunto de datos con las variables ficticias.

<div class="table-wrapper">
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Age</th>
      <th>Fare</th>
      <th>FamilySize</th>
      <th>IsAlone</th>
      <th>Sex_female</th>
      <th>Sex_male</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
      <th>Title_Master</th>
      <th>Title_Misc</th>
      <th>Title_Miss</th>
      <th>Title_Mr</th>
      <th>Title_Mrs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>22.0</td>
      <td>7.2500</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>38.0</td>
      <td>71.2833</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>26.0</td>
      <td>7.9250</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>35.0</td>
      <td>53.1000</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>35.0</td>
      <td>8.0500</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

## Dividir los datos

Dividiremos el conjunto original en entrenamiento y pruebas 

    Datos originales: (891, 19)
    Datos de entrenamiento: (668, 19)
    Datos de prueba: (223, 19)


# Realizar análisis exploratorio

Porcentaje de hombres y mujeres que sobrevivieron.

![png](\images\titanic\output_41_0.png)

Porcentaje de personas de cierta clase social que sobrevivieron.

![png](\images\titanic\output_42_0.png)

Porcentaje de personas que sobrevivieron según su zona de embarque.


![png](\images\titanic\output_43_0.png)

Porcentaje de personas que sobrevivieron según su titulo. 

![png](\images\titanic\output_44_0.png)

Porcentaje de personas que sobrevivieron dependiendo del número de hermanos/cónyuges 
a bordo

![png](\images\titanic\output_45_0.png)

Porcentaje de personas que sobrevivieron dependiendo del número de padres e hijos 
a bordo

![png](\images\titanic\output_46_0.png)

Porcentaje de personas que sobreviveron dependiendo del número de integrantes de 
su familia a bordo.

![png](\images\titanic\output_47_0.png)

Porcentaje de personas que sobrevivieron dependiendo si viajaban solas o no.

![png](\images\titanic\output_48_0.png)


Algunos gráficos extra.

![png](\images\titanic\output_50_0.png)

Mapa de correlación de las columnas del conjunto de datos.

![png](\images\titanic\output_51_0.png)


# Modelar los datos

Tabla que nos indica el rendimiento de los diversos modelos utilizados para resolver
el problema.

<div class="table-wrapper">
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MLA Name</th>
      <th>MLA Parameters</th>
      <th>MLA Train Accuracy Mean</th>
      <th>MLA Test Accuracy Mean</th>
      <th>MLA Test Accuracy 3*STD</th>
      <th>MLA Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>SVC</td>
      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>
      <td>0.835206</td>
      <td>0.827612</td>
      <td>0.0409157</td>
      <td>0.136107</td>
    </tr>
    <tr>
      <th>4</th>
      <td>RandomForestClassifier</td>
      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>
      <td>0.895131</td>
      <td>0.826493</td>
      <td>0.0633724</td>
      <td>0.658607</td>
    </tr>
    <tr>
      <th>12</th>
      <td>XGBClassifier</td>
      <td>{'objective': 'binary:logistic', 'base_score':...</td>
      <td>0.890449</td>
      <td>0.826493</td>
      <td>0.0617704</td>
      <td>0.356233</td>
    </tr>
    <tr>
      <th>8</th>
      <td>NuSVC</td>
      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>
      <td>0.834082</td>
      <td>0.826119</td>
      <td>0.0456629</td>
      <td>0.15811</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ExtraTreesClassifier</td>
      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>
      <td>0.895131</td>
      <td>0.824254</td>
      <td>0.0593284</td>
      <td>0.466217</td>
    </tr>
    <tr>
      <th>3</th>
      <td>GradientBoostingClassifier</td>
      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>
      <td>0.866667</td>
      <td>0.822015</td>
      <td>0.0529916</td>
      <td>0.341489</td>
    </tr>
    <tr>
      <th>9</th>
      <td>DecisionTreeClassifier</td>
      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>
      <td>0.895131</td>
      <td>0.820896</td>
      <td>0.0579501</td>
      <td>0.00795968</td>
    </tr>
    <tr>
      <th>1</th>
      <td>BaggingClassifier</td>
      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>
      <td>0.890075</td>
      <td>0.81903</td>
      <td>0.0631744</td>
      <td>0.0723112</td>
    </tr>
    <tr>
      <th>6</th>
      <td>KNeighborsClassifier</td>
      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>
      <td>0.850375</td>
      <td>0.813806</td>
      <td>0.0690863</td>
      <td>0.00837021</td>
    </tr>
    <tr>
      <th>0</th>
      <td>AdaBoostClassifier</td>
      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>
      <td>0.820412</td>
      <td>0.81194</td>
      <td>0.0498606</td>
      <td>0.307621</td>
    </tr>
    <tr>
      <th>5</th>
      <td>GaussianProcessClassifier</td>
      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>
      <td>0.871723</td>
      <td>0.810448</td>
      <td>0.0492537</td>
      <td>0.668614</td>
    </tr>
    <tr>
      <th>11</th>
      <td>QuadraticDiscriminantAnalysis</td>
      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>
      <td>0.821536</td>
      <td>0.80709</td>
      <td>0.0810389</td>
      <td>0.00862453</td>
    </tr>
    <tr>
      <th>10</th>
      <td>ExtraTreeClassifier</td>
      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>
      <td>0.895131</td>
      <td>0.806716</td>
      <td>0.0557008</td>
      <td>0.0073771</td>
    </tr>
  </tbody>
</table>
</div>

Gráfico de barras con la exactitud de cada uno de los modelos utilizados.

![png](\images\titanic\output_56_0.png)


## Evaluar el rendimiento del modelo

Porcentaje de sobrevivientes femeninos dependiendo de su clase social, la ciudad de
embarcamiento y la tarifa de su boleto.

|Sex    | Pclass | Embarked | FareBin| Surviving percentage|       
|female | 1   |    C     |    (14.454, 31.0]    | 0.666667|
|       |     |          |    (31.0, 512.329]   | 1.000000|
|       |     |    Q     |    (31.0, 512.329]   | 1.000000|
|       |     |    S     |    (14.454, 31.0]    | 1.000000|
|       |     |          |    (31.0, 512.329]   | 0.955556|
|       | 2   |    C     |    (7.91, 14.454]    | 1.000000|
|       |     |          |    (14.454, 31.0]    | 1.000000|
|       |     |          |    (31.0, 512.329]   | 1.000000|
|       |     |    Q     |    (7.91, 14.454]    | 1.000000|
|       |     |    S     |    (7.91, 14.454]    | 0.875000|
|       |     |          |    (14.454, 31.0]    | 0.916667|
|       |     |          |    (31.0, 512.329]   | 1.000000|
|       | 3   |    C     |    (-0.001, 7.91]    | 1.000000|
|       |     |          |    (7.91, 14.454]    | 0.428571|
|       |     |          |    (14.454, 31.0]    | 0.666667|
|       |     |    Q     |    (-0.001, 7.91]    | 0.750000|
|       |     |          |    (7.91, 14.454]    | 0.500000|
|       |     |          |    (14.454, 31.0]    | 0.714286|
|       |     |    S     |    (-0.001, 7.91]    | 0.533333|
|       |     |          |    (7.91, 14.454]    | 0.448276|
|       |     |          |    (14.454, 31.0]    | 0.357143|
|       |     |          |    (31.0, 512.329]   | 0.125000|
    
Porcentaje de sobrevivientes masculinos dependiendo de su titulo. 

| Sex  | Title |Surviving percentage|
|male  |Master   | 0.575000|
|      |Misc     | 0.250000|
|      |Mr       | 0.156673|


## Rendimiento del modelo con Cross-Validation

Evaluación del árbol de decision antes de Cross-Validation

    BEFORE DT Parameters:  {'ccp_alpha': 0.0, 'class_weight': None,
                            'criterion': 'gini', 'max_depth': None, 
                            'max_features': None, 'max_leaf_nodes': None, 
                            'min_impurity_decrease': 0.0, 'min_impurity_split': None, 
                            'min_samples_leaf': 1, 'min_samples_split': 2, 
                            'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 
                            'random_state': 0, 'splitter': 'best'}
    BEFORE DT Training w/bin score mean: 89.51
    BEFORE DT Test w/bin score mean: 82.09
    BEFORE DT Test w/bin score 3*std: +/- 5.57

Evaluación del árbol de decision después de Cross-Validation

    AFTER DT Parameters:  {'criterion': 'gini', 'max_depth': 4,
                           'max_features': None, 'min_samples_leaf': 5, 
                           'min_samples_split': 2, 'random_state': 0, 
                           'splitter': 'best'}
    AFTER DT Training w/bin score mean: 89.25
    AFTER DT Test w/bin score mean: 87.68
    AFTER DT Test w/bin score 3*std: +/- 6.00

Evaluación del árbol de decision antes de recursive feature elimination Cross-Validation 

    BEFORE DT RFE Training Shape Old:  (891, 7)
    BEFORE DT RFE Training Columns Old:  ['Sex_Code' 'Pclass' 'Embarked_Code' 'Title_Code' 'FamilySize'
     'AgeBin_Code' 'FareBin_Code']
    BEFORE DT RFE Training w/bin score mean: 89.51
    BEFORE DT RFE Test w/bin score mean: 82.09
    BEFORE DT RFE Test w/bin score 3*std: +/- 5.57

Evaluación del árbol de decision después de recursive feature 
elimination Cross-Validation 

    AFTER DT RFE Training Shape New:  (891, 6)
    AFTER DT RFE Training Columns New:  ['Sex_Code' 'Pclass' 'Title_Code' 
                                         'FamilySize' 'AgeBin_Code' 'FareBin_Code']
    AFTER DT RFE Training w/bin score mean: 88.16
    AFTER DT RFE Test w/bin score mean: 83.06
    AFTER DT RFE Test w/bin score 3*std: +/- 6.22

Evaluación del árbol de decision después de Cross-Validation usando las nuevas columnas

    AFTER DT RFE Tuned Parameters:  {'criterion': 'gini', 'max_depth': 8,
                                     'max_features': None, 'min_samples_leaf': 5,
                                     'min_samples_split': 2, 'random_state': 0, 
                                     'splitter': 'best'}
    AFTER DT RFE Tuned Training w/bin score mean: 89.23
    AFTER DT RFE Tuned Test w/bin score mean: 87.82
    AFTER DT RFE Tuned Test w/bin score 3*std: +/- 6.81
    ----------

Visualización del árbol de decisión creado por el modelo.

![svg](\images\titanic\output_65_0.svg)

# Validar e implementar el modelado de datos


Votación sin hyper-parametrización

    Hard Voting Training w/bin score mean: 87.90
    Hard Voting Test w/bin score mean: 82.01
    Hard Voting Test w/bin score 3*std: +/- 3.50
    ----------
    Soft Voting Training w/bin score mean: 88.65
    Soft Voting Test w/bin score mean: 82.95
    Soft Voting Test w/bin score 3*std: +/- 5.82
    ----------


|Classifier|Parameter_name|Parameter_value|
|AdaBoostClassifier|'algorithm'| 'SAMME.R'| 
||'learning_rate'| 0.1| 
||'n_estimators'| 300|
||'random_state'| 0|
||with a runtime of 302.35 seconds.|
|ExtraTreesClassifier|'criterion'| 'entropy'| 
||'max_depth'| 6|
||'n_estimators'| 100|
||'random_state'| 0|
||with a runtime of 281.81 seconds.||
|GradientBoostingClassifier
||'criterion'|'friedman_mse'|
||'learning_rate'|0.05| 
||'loss'|'deviance'|
||'max_depth'| 2|
||'n_estimators'|300| 
||'random_state'| 0| 
||with a runtime of 3145.16 seconds.|
|RandomForestClassifier|'criterion'|'entropy'|
||'max_depth'| 6|
||'n_estimators'|100|
||'oob_score'|True|
||'random_state'|0|
||with a runtime of 466.24 seconds.|
|GaussianProcessClassifier|'max_iter_predict'|10| 
||'random_state'|0|
|| with a runtime of 43.35 seconds.|
|KNeighborsClassifier|'algorithm'|'brute'|
||'n_neighbors'|7|
||'weights'|'uniform'|
||with a runtime of 14.40 seconds.|
|SVC|'C'|2|
||'decision_function_shape'|'ovo'|
||'gamma'|0.1|
||'probability'|True|
||'random_state'|0|
||with a runtime of 86.27 seconds.|
|XGBClassifier|'learning_rate'|0.01|
||'max_depth'|4|
||'n_estimators'|300|
||'seed'|0| 
||with a runtime of 271.92 seconds.|
||Total optimization time was 76.86 minutes.|
    
---

Resultados finales con hyperparametros

    Hard Voting w/Tuned Hyperparameters Training w/bin score mean: 85.52
    Hard Voting w/Tuned Hyperparameters Test w/bin score mean: 82.46
    Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 4.90
    ----------
    Soft Voting w/Tuned Hyperparameters Training w/bin score mean: 85.22
    Soft Voting w/Tuned Hyperparameters Test w/bin score mean: 82.46
    Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 5.88
    ----------

Para ver el repositorio completo [¡Click aquí!](https://github.com/KevinDaniel-S/MachineLearning/tree/master/Titanic)
